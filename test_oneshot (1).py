# -*- coding: utf-8 -*-
"""test_OneShot.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CH0K3BFECq-5lnMt1p-E2i06EM-_27aS
"""

# Commented out IPython magic to ensure Python compatibility.
import sys
import numpy as np
import pandas as pd
import pickle
import os
import matplotlib.pyplot as plt
from matplotlib import pylab
# %matplotlib inline
from PIL import Image

import cv2
import time

# %matplotlib inline 
from matplotlib import pyplot as plt

import tensorflow as tf
from keras.models import Sequential
from tensorflow.keras.optimizers import Adam           
from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate
from keras.models import Model

from keras.layers.pooling import MaxPooling2D
from keras.layers.merge import Concatenate
from keras.layers.core import Lambda, Flatten, Dense
from keras.initializers import glorot_uniform

from tensorflow.keras.layers import Layer, InputSpec
from keras.regularizers import l2
from keras import backend as K

from sklearn.utils import shuffle
import imageio as iio

import numpy as np
import numpy.random as rng
from numpy import asarray
from PIL import Image, ImageEnhance, ImageFilter, ImageOps

filepath = '/content/weights.20000.h5'

def initialize_weights(shape, dtype=None):

    return np.random.normal(loc = 0.0, scale = 1e-2, size = shape)

def initialize_bias(shape, dtype=None):
    return np.random.normal(loc = 0.5, scale = 1e-2, size = shape)

def get_siamese_model(input_shape):
    
    # Model architecture based on the one provided in: http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf
    
    
    # Define the tensors for the two input images
    left_input = Input(input_shape)
    right_input = Input(input_shape)
    
    # Convolutional Neural Network
    model = Sequential()
    model.add(Conv2D(64, (10,10), activation='relu', input_shape=input_shape,kernel_initializer=initialize_weights, kernel_regularizer=l2(2e-4)))
    model.add(MaxPooling2D())
    model.add(Conv2D(128, (7,7), activation='relu',
                     kernel_initializer=initialize_weights,
                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))
    model.add(MaxPooling2D())
    model.add(Conv2D(128, (4,4), activation='relu', kernel_initializer=initialize_weights,
                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))
    model.add(MaxPooling2D())
    model.add(Conv2D(256, (4,4), activation='relu', kernel_initializer=initialize_weights,
                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))
    model.add(Flatten())
    model.add(Dense(4096, activation='sigmoid',
                   kernel_regularizer=l2(1e-3),
                   kernel_initializer=initialize_weights,bias_initializer=initialize_bias))
    
    # Generate the encodings (feature vectors) for the two images
    encoded_l = model(left_input)
    encoded_r = model(right_input)
    
    # Add a customized layer to compute the absolute difference between the encodings
    L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))
    L1_distance = L1_layer([encoded_l, encoded_r])
    
    # Add a dense layer with a sigmoid unit to generate the similarity score
    prediction = Dense(1,activation='sigmoid',bias_initializer=initialize_bias)(L1_distance)
    
    # Connect the inputs with the outputs
    siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)
    
    # return the model
    return siamese_net

model = get_siamese_model((128,128,1))

model.load_weights(filepath)
model.summary()

def image_process2(im, min_size=100, fill_color=(255,255,255,0)):
    #img = im.img_to_array(im, dtype='uint8')
    gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)
    kernel = np.ones((5,5), np.uint8)

    # dilation = cv2.dilate(thresh, kernel, iterations = 1)
    canny = cv2.Canny(gray,50,100)
    dialte = cv2.dilate(canny,kernel)
    thresh = cv2.adaptiveThreshold(gray, 255, adaptiveMethod=cv2.ADAPTIVE_THRESH_MEAN_C, thresholdType=cv2.THRESH_BINARY, blockSize=15, C=0)            

    
    print(type(canny))
    negative = cv2.bitwise_not(canny)
    image = Image.fromarray(negative, 'L')
    final = image.resize((128, 128))

    plt.subplot(121),plt.imshow(gray),plt.title('Original')
    plt.xticks([]), plt.yticks([])

    plt.subplot(122),plt.imshow(final),plt.title('Enhanced')
    plt.xticks([]), plt.yticks([])
    plt.imshow(final, cmap='gray', vmin=0, vmax=255)
    plt.show()

    return final

def image_process(im, min_size=100, fill_color=(255,255,255,0)):
    #img = im.img_to_array(im, dtype='uint8')
    gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)
    thresh = cv2.adaptiveThreshold(gray, 255, adaptiveMethod=cv2.ADAPTIVE_THRESH_MEAN_C, thresholdType=cv2.THRESH_BINARY, blockSize=15, C=0)            
    kernel = np.ones((5,5), np.uint8)

    dilation = cv2.dilate(thresh, kernel, iterations = 1)
    canny = cv2.Canny(dilation,10,100)
   

    
    print(type(canny))
    #negative = cv2.bitwise_not(canny)
    image = Image.fromarray(canny, 'L')
    final = image.resize((128, 128))

    plt.subplot(121),plt.imshow(gray),plt.title('Original')
    plt.xticks([]), plt.yticks([])

    plt.subplot(122),plt.imshow(final),plt.title('Threshold, Dialation and Canny edge detection')
    plt.xticks([]), plt.yticks([])
    plt.imshow(final, cmap='gray', vmin=0, vmax=255)
    plt.show()

    return final

def image_process3(im, min_size=100, fill_color=(255,255,255,0)):
    new_im = ImageEnhance.Contrast(im)
    new_im.enhance(1.3)
    new_im = im.resize((128, 128))
    numpyarray = asarray(new_im)
    #numpyarray = numpyarray.img_to_array(new_im, dtype='uint8')
    kernel = np.ones((5,5),np.uint8)
    edges = cv2.Canny(numpyarray,20,100)
    edges = cv2.dilate(edges,kernel,iterations = 1)
    edges = cv2.dilate(numpyarray,kernel, iterations = 1)
    print(type(edges))
    edges = cv2.cvtColor(edges, cv2.COLOR_BGR2GRAY)
    thresh = cv2.adaptiveThreshold(edges, 255, adaptiveMethod=cv2.ADAPTIVE_THRESH_MEAN_C, thresholdType=cv2.THRESH_BINARY, blockSize=15, C=0)
    
    plt.subplot(121),plt.imshow(new_im),plt.title('Original')
    plt.xticks([]), plt.yticks([])

    plt.subplot(122),plt.imshow(thresh),plt.title('Threshold, Dialation and Canny edge detection')
    plt.xticks([]), plt.yticks([])
    #plt.imshow(final, cmap='gray', vmin=0, vmax=255)
    plt.show()


    return thresh

# process3 is the current working one. Has to change our imaging to greyscale
# However, these are screenshots so it'll have to change when we get raw images from
# openCV/vimba

img1 = Image.open('/content/FR1.jpg')
print(type(img1))
img1 = image_process3(img1)
img2 = Image.open('/content/FR3.jpg')
print(type(img2))
img2 = image_process3(img2)

validation_x = np.asarray(img1)
validation_y = np.asarray(img2)


validation_x = validation_x.reshape(1,128,128, 1)
validation_y = validation_y.reshape(1,128,128, 1)
print(type(validation_x))
input = validation_x, validation_y
score = model.predict(input)
print('similarity score: ',score)

